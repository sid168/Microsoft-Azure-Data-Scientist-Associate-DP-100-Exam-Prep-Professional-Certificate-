{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce53d4c2-1de2-40c5-bf47-5f10e4032747",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Exercise: Select Optimal Model by Tuning Hyperparameters\n",
    "\n",
    "Use grid search and cross-validation to tune the hyperparameters from a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3b7d5c5-efbb-4d51-8499-43ef215748fd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Run the following cell to set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da77a282-530b-46d3-a5ce-3ee82a68a1e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b46d737-9f3c-40f4-9aeb-2ae83c444510",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 1: Import the Data\n",
    "\n",
    "Import the data and perform a train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02cd709f-3b12-4f30-a40d-8964a107671f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "cols = [\"index\",\n",
    " \"sample-code-number\",\n",
    " \"clump-thickness\",\n",
    " \"uniformity-of-cell-size\",\n",
    " \"uniformity-of-cell-shape\",\n",
    " \"marginal-adhesion\",\n",
    " \"single-epithelial-cell-size\",\n",
    " \"bare-nuclei\",\n",
    " \"bland-chromatin\",\n",
    " \"normal-nucleoli\",\n",
    " \"mitoses\",\n",
    " \"class\"]\n",
    "\n",
    "cancerDF = (spark.read  # read the data\n",
    "  .option(\"HEADER\", True)\n",
    "  .option(\"inferSchema\", True)\n",
    "  .csv(\"/mnt/training/cancer/biopsy/biopsy.csv\")\n",
    ")\n",
    "\n",
    "cancerDF = (cancerDF    # Add column names and drop nulls\n",
    "  .toDF(*cols)\n",
    "  .withColumn(\"bare-nuclei\", col(\"bare-nuclei\").isNotNull().cast(\"integer\"))\n",
    ")\n",
    "\n",
    "display(cancerDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "caddf120-2755-41d9-bbb4-15b9cb657733",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Perform a train/test split to create `trainCancerDF` and `testCancerDF`.  Put 80% of the data in `trainCancerDF` and use the seed that is set for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea05acba-013e-4e93-be50-377674b449b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "seed = 42\n",
    "trainCancerDF, testCancerDF = cancerDF.randomSplit([0.8, 0.2], seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50f8ceff-ce7a-446a-915e-1f980ce72f2d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 2: Create a Pipeline\n",
    "\n",
    "Create a pipeline `cancerPipeline` that consists of the following stages:<br>\n",
    "\n",
    "1. `indexer`: a `StringIndexer` that takes `class` as an input and outputs the column `is-malignant`\n",
    "2. `assembler`: a `VectorAssembler` that takes all of the other columns as an input and outputs  the column `features`\n",
    "3. `logr`: a `LogisticRegression` that takes `features` as the input and `is-malignant` as the output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a817c86-62a4-481a-b018-c1c1c00fda1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"is-malignant\")\n",
    "assembler = VectorAssembler(inputCols=cols[2:-1], outputCol=\"features\")\n",
    "logr = LogisticRegression(labelCol=\"is-malignant\", featuresCol=\"features\")\n",
    "cancerPipeline = Pipeline(stages=[indexer, assembler, logr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a762002-9965-4e3e-bee8-2652d4b83356",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "dbTest(\"ML1-P-08-02-01\", True, type(indexer) == type(StringIndexer()))\n",
    "dbTest(\"ML1-P-08-02-02\", True, indexer.getInputCol() == 'class')\n",
    "dbTest(\"ML1-P-08-02-03\", True, indexer.getOutputCol() == 'is-malignant')\n",
    "\n",
    "dbTest(\"ML1-P-08-02-04\", True, type(assembler) == type(VectorAssembler()))\n",
    "dbTest(\"ML1-P-08-02-05\", True, assembler.getInputCols() == cols[2:-1])\n",
    "dbTest(\"ML1-P-08-02-06\", True, assembler.getOutputCol() == 'features')\n",
    "\n",
    "dbTest(\"ML1-P-08-02-07\", True, type(logr) == type(LogisticRegression()))\n",
    "dbTest(\"ML1-P-08-02-08\", True, logr.getLabelCol() == \"is-malignant\")\n",
    "dbTest(\"ML1-P-08-02-09\", True, logr.getFeaturesCol() == 'features')\n",
    "\n",
    "dbTest(\"ML1-P-08-02-10\", True, type(cancerPipeline) == type(Pipeline()))\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5162ae6d-572d-4b4e-9c87-2a2ad71b0888",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 3: Create Grid Search Parameters\n",
    "\n",
    "Take a look at the parameters for our `LogisticRegression` object.  Use this to build the inputs to grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cd383b9-81c0-45f1-9dc2-6577d87db1c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(logr.explainParams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80e3cc23-220b-42bd-bcb9-808481f77e06",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Create a `ParamGridBuilder` object with two grids:<br><br>\n",
    "\n",
    "1. A regularization parameter `regParam` of `[0., .2, .8, 1.]`\n",
    "2. Test both with and without an intercept using `fitIntercept`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fefb318c-aad6-49f3-9cdf-d35c2f52eada",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "cancerParamGrid = (ParamGridBuilder()\n",
    "  .addGrid(logr.regParam, [0.0, 0.2, 0.8, 1.0])\n",
    "  .addGrid(logr.fitIntercept, [True, False])\n",
    "  .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b41a4b1-293e-4dae-852e-f73ee0fbbd5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution\n",
    "dbTest(\"ML1-P-08-03-01\", True, type(cancerParamGrid) == list)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3612f4c3-67a8-412e-b136-fb3404754fd7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 4: Perform 3-Fold Cross-Validation\n",
    "\n",
    "Create a `BinaryClassificationEvaluator` object and use it to perform 3-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba75ec9a-f538-4201-b17f-f7a2a75ecba4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "binaryEvaluator = BinaryClassificationEvaluator(\n",
    "  labelCol = \"is-malignant\", \n",
    "  metricName = \"areaUnderROC\"\n",
    ")\n",
    "\n",
    "cancerCV = CrossValidator(\n",
    "  estimator = logr,                   # Estimator (individual model or pipeline)\n",
    "  estimatorParamMaps = cancerParamGrid, # Grid of parameters to try (grid search)\n",
    "  evaluator = binaryEvaluator,        # Evaluator\n",
    "  numFolds = 3,                       # Set k to 3\n",
    "  seed = 42                           # Seed to sure our results are the same if ran again\n",
    ")\n",
    "\n",
    "cancerCVModel = cancerCV.fit(trainCancerDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ab415fc-35ff-4047-bc21-ea8393cfc386",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TEST - Run this cell to test your solution\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "dbTest(\"ML1-P-08-04-01\", True, type(binaryEvaluator) == type(BinaryClassificationEvaluator()))\n",
    "dbTest(\"ML1-P-08-04-02\", True, type(cancerCV) == type(CrossValidator()))\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "175d060b-bde4-4b45-b62a-674b78c396cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 5: Examine the results\n",
    "\n",
    "Take a look at the results.  Which combination of hyperparameters learned the most from the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75d0721d-6f27-4447-bb3a-1a83a0d1adbd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for params, score in zip(cancerCVModel.getEstimatorParamMaps(), cancerCVModel.avgMetrics):\n",
    "  print(\"\".join([param.name+\"\\t\"+str(params[param])+\"\\t\" for param in params]))\n",
    "  print(\"\\tScore: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76d1a8b2-346f-4271-8b02-ee12028c95da",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **Setup: Environment Setup with `%run`**\n",
    "```python\n",
    "%run \"./Includes/Classroom-Setup\"\n",
    "```\n",
    "- `%run` is a magic command in Jupyter notebooks that allows you to run code from another notebook or file.\n",
    "- Here, `\"./Includes/Classroom-Setup\"` is a path to a file that sets up the environment, like preparing libraries, variables, and settings for this notebook.\n",
    "- Running this cell ensures the workspace is ready to use, so we don’t need to manually set up every tool or configuration needed to run the notebook.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Import the Data**\n",
    "#### Code Block 1: Data Import and Initial Cleaning\n",
    "```python\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "cols = [\"index\", \"sample-code-number\", \"clump-thickness\", \"uniformity-of-cell-size\", \"uniformity-of-cell-shape\", \n",
    "        \"marginal-adhesion\", \"single-epithelial-cell-size\", \"bare-nuclei\", \"bland-chromatin\", \"normal-nucleoli\", \n",
    "        \"mitoses\", \"class\"]\n",
    "\n",
    "cancerDF = (spark.read  # read the data\n",
    "  .option(\"HEADER\", True)\n",
    "  .option(\"inferSchema\", True)\n",
    "  .csv(\"/mnt/training/cancer/biopsy/biopsy.csv\"))\n",
    "\n",
    "cancerDF = (cancerDF\n",
    "    .toDF(*cols)  # Add column names\n",
    "    .withColumn(\"bare-nuclei\", col(\"bare-nuclei\").isNotNull().cast(\"integer\")))  # Clean data\n",
    "display(cancerDF)\n",
    "```\n",
    "\n",
    "1. **`from pyspark.sql.functions import col`**:\n",
    "   - Imports the `col` function from PySpark, which is used to reference columns easily in DataFrames.\n",
    "\n",
    "2. **Define Column Names**:\n",
    "   - `cols` is a list of column names that describe each attribute of the data, like `sample-code-number` (an ID for each patient), `clump-thickness` (a feature to analyze), and `class` (the diagnosis, indicating whether the tumor is benign or malignant).\n",
    "\n",
    "3. **Read CSV File**:\n",
    "   - `spark.read` initiates reading data with Spark's `DataFrame` API.\n",
    "   - `.option(\"HEADER\", True)` tells Spark to treat the first row as column names.\n",
    "   - `.option(\"inferSchema\", True)` allows Spark to automatically detect data types (e.g., integer, string) for each column.\n",
    "   - `.csv(\"/mnt/training/cancer/biopsy/biopsy.csv\")` loads the file stored at this path into a DataFrame called `cancerDF`.\n",
    "\n",
    "4. **Rename Columns**:\n",
    "   - `.toDF(*cols)` renames columns in `cancerDF` to match the list `cols`.\n",
    "\n",
    "5. **Handle Missing Values**:\n",
    "   - `.withColumn(\"bare-nuclei\", col(\"bare-nuclei\").isNotNull().cast(\"integer\"))`:\n",
    "     - `col(\"bare-nuclei\").isNotNull()` replaces any missing values in the \"bare-nuclei\" column.\n",
    "     - `.cast(\"integer\")` ensures that all values are of integer type.\n",
    "\n",
    "6. **Display the DataFrame**:\n",
    "   - `display(cancerDF)` shows the DataFrame in a table format for easy viewing.\n",
    "\n",
    "#### Code Block 2: Split Data into Training and Testing Sets\n",
    "```python\n",
    "seed = 42\n",
    "trainCancerDF, testCancerDF = cancerDF.randomSplit([0.8, 0.2], seed=seed)\n",
    "```\n",
    "\n",
    "1. **Set a Seed**:\n",
    "   - `seed = 42` sets a random seed, ensuring that the data split will be consistent every time we run the code.\n",
    "\n",
    "2. **Random Split**:\n",
    "   - `cancerDF.randomSplit([0.8, 0.2], seed=seed)`:\n",
    "     - Splits `cancerDF` into two parts:\n",
    "       - **80%** of the data goes to `trainCancerDF` for training the model.\n",
    "       - **20%** goes to `testCancerDF` for evaluating the model.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Create a Pipeline**\n",
    "\n",
    "```python\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"is-malignant\")\n",
    "assembler = VectorAssembler(inputCols=cols[2:-1], outputCol=\"features\")\n",
    "logr = LogisticRegression(labelCol=\"is-malignant\", featuresCol=\"features\")\n",
    "\n",
    "cancerPipeline = Pipeline(stages=[indexer, assembler, logr])\n",
    "```\n",
    "\n",
    "1. **Import Required Libraries**:\n",
    "   - `Pipeline` helps to create and apply a series of steps.\n",
    "   - `LogisticRegression` is the machine learning model we’ll train.\n",
    "   - `StringIndexer` converts labels (like \"benign\" or \"malignant\") into numeric values.\n",
    "   - `VectorAssembler` combines multiple columns into a single \"features\" vector.\n",
    "\n",
    "2. **Stage 1 - Indexing**:\n",
    "   - `indexer = StringIndexer(inputCol=\"class\", outputCol=\"is-malignant\")`:\n",
    "     - Takes the \"class\" column (indicating benign or malignant tumors) and assigns it to a new column \"is-malignant\" as numerical labels (0 or 1).\n",
    "\n",
    "3. **Stage 2 - Assemble Features**:\n",
    "   - `assembler = VectorAssembler(inputCols=cols[2:-1], outputCol=\"features\")`:\n",
    "     - Takes feature columns (like cell size, thickness, etc.) and combines them into a single \"features\" column. This \"features\" column is what the model will analyze.\n",
    "\n",
    "4. **Stage 3 - Model Setup**:\n",
    "   - `logr = LogisticRegression(labelCol=\"is-malignant\", featuresCol=\"features\")`:\n",
    "     - Initializes a Logistic Regression model that will take \"features\" as inputs and predict \"is-malignant.\"\n",
    "\n",
    "5. **Pipeline Creation**:\n",
    "   - `cancerPipeline = Pipeline(stages=[indexer, assembler, logr])`:\n",
    "     - Combines all three steps into a single pipeline so we can run all transformations and model training in one go.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Set Up Grid Search Parameters**\n",
    "\n",
    "#### Code Block 1: Print Logistic Regression Parameters\n",
    "```python\n",
    "print(logr.explainParams())\n",
    "```\n",
    "\n",
    "- `logr.explainParams()` prints out a list of all the configurable parameters for Logistic Regression, like `regParam` (controls overfitting) and `fitIntercept` (decides whether the model should include an intercept term).\n",
    "\n",
    "#### Code Block 2: Create Parameter Grid\n",
    "```python\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "cancerParamGrid = (ParamGridBuilder()\n",
    "  .addGrid(logr.regParam, [0.0, 0.2, 0.8, 1.0])\n",
    "  .addGrid(logr.fitIntercept, [True, False])\n",
    "  .build())\n",
    "```\n",
    "\n",
    "1. **Initialize ParamGridBuilder**:\n",
    "   - `ParamGridBuilder()` helps to build a grid of parameters for tuning the model.\n",
    "\n",
    "2. **Define Hyperparameters to Test**:\n",
    "   - `.addGrid(logr.regParam, [0.0, 0.2, 0.8, 1.0])`:\n",
    "     - Adds a range of values to test for `regParam` (regularization parameter).\n",
    "   - `.addGrid(logr.fitIntercept, [True, False])`:\n",
    "     - Tests whether including an intercept (fitIntercept) improves performance.\n",
    "\n",
    "3. **Build the Grid**:\n",
    "   - `.build()` finalizes the parameter grid, making it ready to test.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Perform 3-Fold Cross-Validation**\n",
    "\n",
    "```python\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "binaryEvaluator = BinaryClassificationEvaluator(\n",
    "  labelCol = \"is-malignant\", \n",
    "  metricName = \"areaUnderROC\"\n",
    ")\n",
    "\n",
    "cancerCV = CrossValidator(\n",
    "  estimator = logr,                   # Model (or pipeline) to evaluate\n",
    "  estimatorParamMaps = cancerParamGrid, # Parameter grid\n",
    "  evaluator = binaryEvaluator,        # Metric to evaluate performance\n",
    "  numFolds = 3,                       # 3-fold cross-validation\n",
    "  seed = 42                           # Random seed\n",
    ")\n",
    "\n",
    "cancerCVModel = cancerCV.fit(trainCancerDF)\n",
    "```\n",
    "\n",
    "1. **Create an Evaluator**:\n",
    "   - `BinaryClassificationEvaluator` is used to measure how well the model distinguishes between two classes (malignant vs. benign).\n",
    "   - `metricName = \"areaUnderROC\"` specifies the metric \"area under ROC\" curve, which measures how well the model separates the two classes.\n",
    "\n",
    "2. **Set Up Cross-Validation**:\n",
    "   - `CrossValidator` trains multiple versions of the model using different parameter settings from `cancerParamGrid` and evaluates their performance using `binaryEvaluator`.\n",
    "   - `numFolds = 3` specifies that 3-fold cross-validation should be used to test each model 3 times on different parts of the data.\n",
    "\n",
    "3. **Train the Model with Cross-Validation**:\n",
    "   - `cancerCVModel = cancerCV.fit(trainCancerDF)` runs cross-validation on the training data and finds the best model parameters.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5: Examine the Results**\n",
    "\n",
    "```python\n",
    "for params, score in zip(cancerCVModel.getEstimatorParamMaps(), cancerCVModel.avgMetrics):\n",
    "  print(\"\".join([param.name+\"\\t\"+str(params[param])+\"\\t\" for param in params]))\n",
    "  print(\"\\tScore: {}\".format(score))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "1. **Get Parameter-Score Pairs**:\n",
    "   - `cancerCVModel.getEstimatorParamMaps()` provides the list of parameter combinations tested.\n",
    "   - `cancerCVModel.avgMetrics` provides the average score for each parameter combination.\n",
    "\n",
    "2. **Print Parameters and Scores**:\n",
    "   - `for params, score in zip(...):` loops through each parameter combination and its corresponding score.\n",
    "   - `print(\"\".join([...]))` and `print(\"\\tScore: ...\")` print each parameter combination along with its score to see which settings performed best. \n",
    "\n",
    "This final output helps identify the best parameter settings for predicting if a case is malignant or benign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32d01efe-0322-4b11-b4e1-49d56c6b1158",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Setup: Getting the Environment Ready\n",
    "The first line of code, `%run \"./Includes/Classroom-Setup\"`, is like preparing your workspace. It sets up the environment in a way that makes sure everything runs smoothly. Think of it as preparing all the tools you need before you start working.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Import the Data\n",
    "1. **Load the Data**:\n",
    "   - First, the data about cancer patients is loaded. Each row represents a person, and each column is a different measurement about them (like cell size, thickness, etc.), which might help us predict if they have cancer.\n",
    "   - This data is read into a `DataFrame`, a kind of table that organizes data nicely for us to work with.\n",
    "\n",
    "2. **Clean the Data**:\n",
    "   - We give each column a name to make it easier to understand.\n",
    "   - One column, \"bare-nuclei,\" sometimes has missing information, so we fix it by replacing missing values with a number that represents \"unknown.\"\n",
    "\n",
    "3. **Split the Data**:\n",
    "   - We divide the data into two parts:\n",
    "      - **Training Data (80%)**: Used to teach the model how to make predictions.\n",
    "      - **Testing Data (20%)**: Used to see how well the model learned.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Create a Pipeline\n",
    "A **pipeline** is like an assembly line for building a model. It has three stages:\n",
    "\n",
    "1. **Stage 1 - Label the Classes**:\n",
    "   - We create a new column, \"is-malignant,\" that labels whether each case is cancerous (malignant) or not. This step helps the model understand what it’s supposed to predict.\n",
    "\n",
    "2. **Stage 2 - Assemble the Features**:\n",
    "   - All the columns that describe the patient (like cell size and shape) are combined into one big list, called \"features.\" The model will look at this list to find patterns.\n",
    "\n",
    "3. **Stage 3 - Create the Model**:\n",
    "   - We make a **logistic regression model**, which is a type of model that can be used to predict categories, like \"cancer\" or \"no cancer.\"\n",
    "\n",
    "4. **Put it All Together**:\n",
    "   - All three steps are put into a pipeline called `cancerPipeline`, so we can run everything at once when we're ready.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Set Up Grid Search Parameters\n",
    "**Grid search** helps find the best settings (or **hyperparameters**) for our model.\n",
    "\n",
    "1. **Set Different Values to Test**:\n",
    "   - Two important settings are tested here:\n",
    "      - `regParam` (short for \"regularization parameter\"): Controls how flexible or strict the model is. We try values like `0.0`, `0.2`, `0.8`, and `1.0`.\n",
    "      - `fitIntercept`: Decides if the model should use an intercept, like adding a starting point to the equation.\n",
    "   - `ParamGridBuilder` is used to test different combinations of these settings.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Perform 3-Fold Cross-Validation\n",
    "**Cross-validation** is like taking multiple \"practice tests\" to check how well the model might work in real life.\n",
    "\n",
    "1. **Set Up a Test Evaluator**:\n",
    "   - We use an evaluator to see how well each model version performs. The evaluator looks at how well the model separates cases with cancer from those without cancer, using a scoring method called **ROC (Receiver Operating Characteristic)**.\n",
    "\n",
    "2. **Run Cross-Validation**:\n",
    "   - We test each combination of hyperparameters (from Step 3) with the training data. The cross-validation splits the data into 3 parts (or folds), trains the model on each part, and then checks its performance on the remaining parts.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5: Examine the Results\n",
    "1. **Check Each Model's Score**:\n",
    "   - For each combination of settings tested, we print out the parameters and their score. The scores help us see which settings produced the best model for making predictions. \n",
    "\n",
    "Each time we run the notebook, it will choose the best model settings based on these tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a2240ac-868a-4d48-9d68-9d90f6760285",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4186528732196364,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "2. Exercise Model Selection",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
