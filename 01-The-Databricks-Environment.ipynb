{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa7f8512-636a-4a4a-8ebc-c76904bc47e6",
     "showTitle": false, 
     "title": ""
    }
   },
   "source": [
    "# Work with Notebooks\n",
    "\n",
    "**Technical Accomplishments:**\n",
    "- Set the stage for learning on the Databricks platform\n",
    "- Demonstrate how to develop & execute code within a notebook\n",
    "- Introduce the Databricks File System (DBFS)\n",
    "- Introduce `dbutils`\n",
    "- Review the various \"Magic Commands\"\n",
    "- Review various built-in commands that facilitate working with the notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ec86da3-bad8-4167-9224-dac71093bd77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Feeling Lost?\n",
    "The [Databricks Unified Support Portal](https://help.databricks.com/s/) is a great place to search forums and documentation for Databricks and Spark.\n",
    "\n",
    "Databricks also offers [multiple tiers for dedicated support](https://databricks.com/support)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e2d02a1-ef75-4529-83c4-11eab448b18b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Scala, Python, R, SQL\n",
    "\n",
    "* Each notebook is tied to a specific language: **Scala**, **Python**, **SQL** or **R**\n",
    "* Run the cell below using one of the following options:\n",
    "  * **CTRL+ENTER** or **CMD+RETURN**\n",
    "  * **SHIFT+ENTER** or **SHIFT+RETURN** to run the cell and move to the next one\n",
    "  * Using **Run Cell**, **Run All Above** or **Run All Below** as seen here<br/><img style=\"box-shadow: 5px 5px 5px 0px rgba(0,0,0,0.25); border: 1px solid rgba(0,0,0,0.25);\" src=\"https://files.training.databricks.com/images/notebook-cell-run-cmd.png\"/>\n",
    "\n",
    "Feel free to tweak the code below if you like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2306a009-75af-43e8-a1aa-4772aea1dbfc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"I'm running Python!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40cf0971-b313-47ec-9d3c-bee294613c5b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Magic Commands\n",
    "* Magic Commands are specific to the Databricks notebooks\n",
    "* They are very similar to Magic Commands found in comparable notebook products\n",
    "* These are built-in commands that do not apply to the notebook's default language\n",
    "* A single percent (%) symbol at the start of a cell identifies a Magic Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53c70d31-c27e-471a-9dc2-2d70dba5e1be",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Magic Command: &percnt;sh\n",
    "For example, **&percnt;sh** allows us to execute shell commands on the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a28e6d3-61c0-488e-8f6d-908bb5ecdf40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh ps | grep 'java'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76ad145d-1cc9-4114-846a-80308968f713",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Magic Command: Other Languages\n",
    "Additional Magic Commands allow for the execution of code in languages other than the notebook's default:\n",
    "* **&percnt;python**\n",
    "* **&percnt;scala**\n",
    "* **&percnt;sql**\n",
    "* **&percnt;r**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cae6d96-fc10-4657-a933-6384124dda90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "\n",
    "println(\"Hello Scala!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dc38281-d342-41f8-ae5d-e9ab59f7b725",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "print(\"Hello Python!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db42e60e-16e3-4629-9648-9c3a3c7f7fa9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%r\n",
    "\n",
    "print(\"Hello R!\", quote=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cff1965e-9d33-4093-8afe-57ffac4a5b0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "select \"Hello SQL!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab888f62-9e5a-4a5c-ad61-b01eda9d140d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Magic Command: &percnt;md\n",
    "\n",
    "Our favorite Magic Command **&percnt;md** allows us to render Markdown in a cell:\n",
    "* Double click this cell to begin editing it\n",
    "* Then hit `Esc` to stop editing\n",
    "\n",
    "# Title One\n",
    "## Title Two\n",
    "### Title Three\n",
    "\n",
    "This is a test of the emergency broadcast system. This is only a test.\n",
    "\n",
    "This is text with a **bold** word in it.\n",
    "\n",
    "This is text with an *italicized* word in it.\n",
    "\n",
    "This is an ordered list\n",
    "0. once\n",
    "0. two\n",
    "0. three\n",
    "\n",
    "This is an unordered list\n",
    "* apples\n",
    "* peaches\n",
    "* bananas\n",
    "\n",
    "Links/Embedded HTML: <a href=\"http://bfy.tw/19zq\" target=\"_blank\">What is Markdown?</a>\n",
    "\n",
    "Images:\n",
    "![Spark Engines](https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png)\n",
    "\n",
    "And of course, tables:\n",
    "\n",
    "| Name  | Age | Sex    |\n",
    "|-------|-----|--------|\n",
    "| Tom   | 32  | Male   |\n",
    "| Mary  | 29  | Female |\n",
    "| Dick  | 73  | Male   |\n",
    "| Sally | 55  | Female |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2681d30c-b17f-4e12-bd29-400ff4195ea6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Magic Command: &percnt;run\n",
    "* You can run a notebook from another notebook by using the Magic Command **%run**\n",
    "* All variables & functions defined in that other notebook will become available in your current notebook\n",
    "\n",
    "For example, The following cell should fail to execute because the variable `username` has not yet been declared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "383ab461-037d-47c1-89d4-9c7a14183fa3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"username: \" + username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0a0daca-5b7c-40c9-bf3a-487c0c504d78",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "But we can declare it and a handful of other variables and functions buy running this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb40adab-a4ea-438f-8388-af6bb771f003",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d33e52c2-0017-4d90-b066-fa8ecb6aaaa2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In this case, the notebook `Classroom Setup` declares the following:\n",
    "  * The variable `username`\n",
    "  * The variable `userhome`\n",
    "  * The function `assertSparkVersion(..)`\n",
    "  * And others..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85973599-dbd1-410f-b42e-572b30eeb3cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"username: \" + username)\n",
    "print(\"userhome: \" + userhome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ae388c9-94ce-4db6-acc8-016ba6b950e9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We will use those variables and functions throughout this class.\n",
    "\n",
    "One of the other things `Classroom Setup` does for us is to mount all the datasets needed for this class into the Databricks File System."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4247928f-8ae8-463a-9125-3399c0908773",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Databricks File System - DBFS\n",
    "* DBFS is a layer over a cloud-based object store\n",
    "* Files in DBFS are persisted to the object store\n",
    "* The lifetime of files in the DBFS are **NOT** tied to the lifetime of our cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dc18ac6-a747-4105-b8d0-5636c7217a8b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Mounting Data into DBFS\n",
    "* Mounting other object stores into DBFS gives Databricks users access via the file system\n",
    "* This is just one of many techniques for pulling data into Spark\n",
    "* The datasets needed for this class have already been mounted for us with the call to `%run \"../Includes/Classroom Setup\"`\n",
    "* We will confirm that in just a few minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32ce5d83-7014-400f-93ae-66e0b0bb1feb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "See also <a href=\"https://docs.azuredatabricks.net/user-guide/dbfs-databricks-file-system.html\" target=\"_blank\">Databricks File System - DBFS</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a46f1fb7-4ba7-496c-a2b2-50a4fa9d3644",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Databricks Utilities - dbutils\n",
    "* You can access the DBFS through the Databricks Utilities class (and other file IO routines).\n",
    "* An instance of DBUtils is already declared for us as `dbutils`.\n",
    "* For in-notebook documentation on DBUtils you can execute the command `dbutils.help()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c9effd7-87b4-408f-a0e1-af3c5b7aa472",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "See also <a href=\"https://docs.azuredatabricks.net/user-guide/dbutils.html\" target=\"_blank\">Databricks Utilities - dbutils</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "036f1f37-2be0-4206-869e-9ba614c44df0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc8f8d63-9ba9-4150-bf55-55c09a95235e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Additional help is available for each sub-utility:\n",
    "* `dbutils.fs.help()`\n",
    "* `dbutils.meta.help()`\n",
    "* `dbutils.notebook.help()`\n",
    "* `dbutils.widgets.help()`\n",
    "\n",
    "Let's take a look at the file system utilities, `dbutils.fs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7afaca37-f48f-4ab5-9b26-5b723a1fc369",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33e84f36-0729-417b-96ae-b813cf6a7fe8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### dbutils.fs.mounts()\n",
    "* As previously mentioned, all our datasets should already be mounted\n",
    "* We can use `dbutils.fs.mounts()` to verify that assertion\n",
    "* This method returns a collection of `MountInfo` objects, one for each mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fa7c8af-ae55-47a5-ba39-14c766466d43",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mounts = dbutils.fs.mounts()\n",
    "\n",
    "for mount in mounts:\n",
    "  print(mount.mountPoint + \" >> \" + mount.source)\n",
    "\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ee75b53-11ce-4640-a080-db2e1879182a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### dbutils.fs.ls(..)\n",
    "* And now we can use `dbutils.fs.ls(..)` to view the contents of that mount\n",
    "* This method returns a collection of `FileInfo` objects, one for each item in the specified directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68f93136-9642-40a9-a887-3b9c40b7e1e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "See also <a href=\"https://docs.azuredatabricks.net/api/latest/dbfs.html#dbfsfileinfo\" target=\"_blank\">FileInfo</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d84b069f-403b-4496-9197-ff88e6ae2203",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "files = dbutils.fs.ls(\"/mnt/training/\")\n",
    "\n",
    "for fileInfo in files:\n",
    "  print(fileInfo.path)\n",
    "\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6042fc73-f334-4d65-b6a9-ef23265c8595",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### display(..)\n",
    "\n",
    "Besides printing each item returned from `dbutils.fs.ls(..)` we can also pass that collection to another Databricks specific command called `display(..)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2419e822-0583-47e9-9545-3b0c17c13155",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "files = dbutils.fs.ls(\"/mnt/training/\")\n",
    "\n",
    "display(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47482a03-99e2-4d69-8864-08c8fafd5c78",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The `display(..)` command is overloaded with a lot of other capabilities:\n",
    "* Presents up to 1000 records.\n",
    "* Exporting data as CSV.\n",
    "* Rendering a multitude of different graphs.\n",
    "* Rendering geo-located data on a world map.\n",
    "\n",
    "And as we will see later, it is also an excellent tool for previewing our data in a notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6bb48a3-c442-442c-a0df-8d296f4befc8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Magic Command: &percnt;fs\n",
    "\n",
    "There is at least one more trick for looking at the DBFS.\n",
    "\n",
    "It is a wrapper around `dbutils.fs` and it is the Magic Command known as **&percnt;fs**.\n",
    "\n",
    "The following call is equivalent to the previous call, `display( dbutils.fs.ls(\"/mnt/training\") )` - there is no real difference between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62a40304-8961-4acc-8ad8-fe338f0ff5a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /mnt/training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2899a8f4-8435-4280-849d-f996589adbce",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Learning More\n",
    "\n",
    "We like to encourage you to explore the documentation to learn more about the various features of the Databricks platform and notebooks.\n",
    "* <a href=\"https://docs.azuredatabricks.net/user-guide/index.html\" target=\"_blank\">User Guide</a>\n",
    "* <a href=\"https://docs.databricks.com/user-guide/getting-started.html\" target=\"_blank\">Getting Started with Databricks</a>\n",
    "* <a href=\"https://docs.azuredatabricks.net/user-guide/notebooks/index.html\" target=\"_blank\">User Guide / Notebooks</a>\n",
    "* <a href=\"https://docs.databricks.com/user-guide/notebooks/index.html#importing-notebooks\" target=\"_blank\">Importing notebooks - Supported Formats</a>\n",
    "* <a href=\"https://docs.azuredatabricks.net/administration-guide/index.html\" target=\"_blank\">Administration Guide</a>\n",
    "* <a href=\"https://docs.databricks.com/user-guide/clusters/index.html\" target=\"_blank\">Cluster Configuration</a>\n",
    "* <a href=\"https://docs.azuredatabricks.net/api/index.html\" target=\"_blank\">REST API</a>\n",
    "* <a href=\"https://docs.azuredatabricks.net/release-notes/index.html\" target=\"_blank\">Release Notes</a>\n",
    "* <a href=\"https://docs.azuredatabricks.net\" target=\"_blank\">And much more!</a>\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3265501922179808,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "01-The-Databricks-Environment",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
